{"name":"Visual Search Framework [iOS]","tagline":"Aumentia Visual Search Framework: Image Recognition and QR / bar code reader","body":"### The Visual Search Framework includes:\r\n![VS Framework Logo](https://s3-us-west-1.amazonaws.com/aumentia/wiki/home/icon55.png)\r\n![Recognise within milliseconds any image](https://s3-us-west-1.amazonaws.com/aumentia/wiki/home/visualsearch_small.png)\r\n* Add visual search to your app.\r\n* Real time image matching (50-100 images per pool).\r\n* Insert images from local resources: works offline!\r\n* Insert images from URL.\r\n* White Label.\r\n* QR code scan support.\r\n* Scan up to 4 QR / bar codes at a time.\r\n* Define you matching areas: Regions of Interest.\r\n* Match images and QR codes simultaneously \r\n\r\n## Content\r\n*  [Configure VS Framework](https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Configure-VS-Framework)\r\n*  [Add & Remove Images](https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Add-&-Remove-Images)\r\n*  [Read QR bar codes](https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Read-QR---bar-codes)\r\n*  [Crop frames](https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Crop-frames)\r\n*  [API](http://api.aumentia.com)\r\n*  [Featured Apps using the VS Framework](https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Featured-Apps-using-the-VS-Framework)\r\n\r\n## Configure the framework\r\n\r\n* Include the following frameworks\r\n\r\n![Include these frameworks](https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs1.png)\r\n\r\n\r\n* Add the below linker flags:\r\n`-mthumb -lstdc++ -lz -lm -mfpu=neon -mtune=cortex-a8` \r\n\r\n![Other Linker Flags](https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs2.png)\r\n\r\n\r\n* Include the **VS.framework** and add its protocols \r\n```objective-c\r\n#import <VS/vsPlugin.h>\r\n...\r\n \r\n@interface ViewController : UIViewController<imageMatchedProtocol, QRMatchedProtocol,...>\r\n\r\n@end\r\n```\r\n\r\n* The .m file where you include the framework must be compiled supporting cpp, so change the “**File Type**” to “**Objective-C++ Source**“. \r\n\r\n![objc++](https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs3.png)\r\n\r\n* Add your own camera. You should create a protocol that will be receiving each output frame. We will send this frame to the engine to analyse it.\r\n We provide the CaptureSessionManager class to take care of all the camera aspects.\r\n You just will need to set it up:\r\n\r\n```objective-c\r\n#pragma mark - Add external camera\r\n \r\n- (void)initCapture {\r\n     \r\n    // init capture manager\r\n    _captureManager = [[CaptureSessionManager alloc] init];\r\n     \r\n    _captureManager.delegate = self;\r\n     \r\n    // set video streaming quality\r\n    _captureManager.captureSession.sessionPreset = AVCaptureSessionPresetMedium;   //480x360\r\n     \r\n    [_captureManager setOutPutSetting:[NSNumber numberWithInt:kCVPixelFormatType_32BGRA]]; //kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange\r\n     \r\n    [_captureManager addVideoInput:AVCaptureDevicePositionBack]; //AVCaptureDevicePositionFront / AVCaptureDevicePositionBack\r\n    [_captureManager addVideoOutput];\r\n    [_captureManager addVideoPreviewLayer];\r\n     \r\n    CGRect layerRect = self.view.bounds;\r\n     \r\n    [[_captureManager previewLayer] setOpaque: 0];\r\n    [[_captureManager previewLayer] setBounds:layerRect ];\r\n    [[_captureManager previewLayer] setPosition:CGPointMake( CGRectGetMidX(layerRect), CGRectGetMidY(layerRect) ) ];\r\n     \r\n    // create a view, on which we attach the AV Preview layer\r\n    _cameraView = [[UIView alloc] initWithFrame:self.view.bounds];\r\n    [[_cameraView layer] addSublayer:[_captureManager previewLayer]];\r\n     \r\n    // add the view we just created as a subview to the View Controller's view\r\n    [self.view addSubview: _cameraView];\r\n     \r\n    // start !\r\n    [self performSelectorInBackground:@selector(start_captureManager) withObject:nil];\r\n     \r\n}\r\n \r\n- (void)removeCapture\r\n{\r\n    [_captureManager.captureSession stopRunning];\r\n    [_cameraView removeFromSuperview];\r\n    _captureManager     = nil;\r\n    _cameraView         = nil;\r\n}\r\n \r\n- (void)start_captureManager\r\n{\r\n    @autoreleasepool\r\n    {\r\n        [[_captureManager captureSession] startRunning];\r\n    }\r\n}\r\n```\r\nand implement its callbacks:\r\n\r\n```objective-c\r\n#pragma mark - External Camera Delegates\r\n \r\n- (void)processNewCameraFrameRGB:(CVImageBufferRef)cameraFrame\r\n{\r\n    [_myVs processRGBFrame:cameraFrame saveImageToPhotoAlbum:NO ];\r\n}\r\n \r\n- (void)processNewCameraFrameYUV:(CVImageBufferRef)cameraFrame\r\n{\r\n    [_myVs processYUVFrame:cameraFrame saveImageToPhotoAlbum:NO];\r\n}\r\n```\r\n\r\n## Add & Remove Images\r\n\r\nThe library matches the camera output frames with the images stored in its database. The search process takes few ms, this means it is real time. The processing time depends on the device and on the amount of images you add to the system. Typically you can add around **50 images up to 100** in the most powerful devices.\r\nYou can both add images from **URL** or from your **local** resources.\r\nYou can also set up your unique Id or let the library do it for you.\r\n\r\nTo add images you can use these functions:\r\n\r\n```objective-c\r\n- (NSInteger) insertImage:(UIImage*)image;\r\n \r\n- (NSInteger) insertImageFromURL:(NSURL*)imageUrl;\r\n \r\n- (BOOL) insertImage:(UIImage*)image withId:(NSInteger)uId;\r\n \r\n- (BOOL) insertImageFromURL:(NSURL*)imageUrl withId:(NSInteger)uId;\r\n```\r\n\r\nYou can also delete a single image providing its unique id:\r\n\r\n```objective-c\r\n- (BOOL) deleteImage:(NSInteger)uId;\r\n```\r\n\r\nOr delete all the images in the db.\r\n\r\n```objective-c\r\n- (BOOL) deleteAllImages;\r\n```\r\n\r\n### How to create a “good pool”\r\n\r\nA good pool is a group of images that have good features, are different between them and can be easily matched without getting any false positive. In order to assure that you create good pools we provide several functions:\r\n\r\n* **setMatchingThreshold**: The images added to the system receive a punctuation between 0 and 10 indicating how “rich” is the image (amounf of good features for matching). The more close to 10, easier is to match the image and more difficult is to get a false positive.\r\n    Setting this param, the user decides the minimum quality of his pool of images.\r\n    \r\n* Before adding an image to your pool you can get its punctuation with the **getImageScore** function.\r\n \r\n* You can also adjust the **MinFeatures** and **MaxFeatures** params:\r\n\r\n    **MinFeatures**: Minimum amount of features accepted to insert an image in the system.\r\n    * The higher it is the most feature-rich images will be required to be inserted.\r\n    * This value is related with the threshold: the higher the most restrictive the threshold will be.\r\n    * **Default value is 50.**\r\n\r\n    **MaxFeatures**: Maximum amount of features accepted to match an image.\r\n    * When an image / frame is going to be matched against the images already inserted in the system, the engine\r\n    * extract the best features and compares them with the ones of the images in the system.\r\n    * The higher it is the most features will be accepted in the matching process.\r\n    * The higher it is the better will be the matching quality but the matching speed will be reduced.\r\n    * **Default value is 50.**\r\n    \r\n* It is recommended to use the motion filter. This filter checks if the device is moving and if so, it does not look for matches avoiding false positive with undefined frames while moving: \r\n\r\n```objective-c\r\n- (void)initMotionDetection;\r\n \r\n- (void)removeMotionDetection;\r\n```\r\n\r\n### Detection callbacks\r\n\r\nFirst you need to implement the **CaptureSessionManger** class callbacks. Remember that those callbacks will provide you the video feed frames, frames that you will send to be analysed by the library.\r\n\r\n```objective-c\r\n- (void)processNewCameraFrameRGB:(CVImageBufferRef)cameraFrame\r\n{\r\n    [_myVs processRGBFrame:cameraFrame saveImageToPhotoAlbum:NO ];\r\n}\r\n```\r\n\r\n```objective-c \r\n- (void)processNewCameraFrameYUV:(CVImageBufferRef)cameraFrame\r\n{\r\n    [_myVs processYUVFrame:cameraFrame saveImageToPhotoAlbum:NO];\r\n}\r\n```\r\n\r\nThen the engine will give you back the matching results: -1 if no image is recognised, != -1 if an image has been matched, being that result its unique id.\r\n\r\n```objective-c \r\n- (void)imageMatchedResult:(NSInteger)uId\r\n{\r\n    if (uId != -1)\r\n    {\r\n        VSLog(@\"Image detected --> %d\", uId);\r\n    }\r\n}\r\n```\r\n\r\n## QR / bar codes\r\n\r\nThis library is capable also to read QR and bar codes.\r\nThe supported standards are:\r\n*     UPC-A\r\n*     UPC-E\r\n*     EAN-8\r\n*     EAN-13\r\n*     Code 39\r\n*     Code 93\r\n*     Code 128\r\n*     ITF\r\n*     Codabar\r\n*     RSS-14 (all variants)\r\n*     QR Code\r\n*     Data Matrix\r\n*     Aztec (‘beta’ quality)\r\n*     PDF 417 (‘alpha’ quality)\r\n\r\nIn order to enable this feature, set **search_mode** to **search_QRcodes** or **search_all**\r\n\r\n### Multiple QR / bar codes\r\n\r\nYou can also read **multiple QR / bar codes a time**. To do that you will need to define ROIs, regions of interest, where to “look for” readable codes.\r\n\r\n```objective-c\r\n- (void)addQRRois\r\n{\r\n    // Add regions to match several QR / bar codes\r\n    Roi *ROI1 = [[Roi alloc] initWithRect:CGRectMake(0, 0, 160, 240)];\r\n    Roi *ROI2 = [[Roi alloc] initWithRect:CGRectMake(0, 240, 160, 240)];\r\n    Roi *ROI3 = [[Roi alloc] initWithRect:CGRectMake(160, 0, 160, 240)];\r\n    Roi *ROI4 = [[Roi alloc] initWithRect:CGRectMake(160, 240, 160, 240)];\r\n        \r\n    // Add them to the system\r\n    [_myVs addQRRect:ROI1];\r\n    [_myVs addQRRect:ROI2];\r\n    [_myVs addQRRect:ROI3];\r\n    [_myVs addQRRect:ROI4];\r\n}\r\n```\r\n\r\n### QR codes callbacks\r\n\r\nWhen a single or multiple QR / bar code is/are read, the QRMatchedProtocol protocol will give you the value/s:\r\n\r\n```objective-c\r\n\r\n- (void)singleQRMatchedResult:(NSString *)res\r\n{\r\n    if ( ![res isEqualToString:@\"\"])\r\n    {\r\n        VSLog(@\"QR / bar code detected --> %@\", res);\r\n    }\r\n}\r\n \r\n- (void)multipleQRMatchedResult:(NSArray *)codes\r\n{\r\n    NSString *code = @\"\";\r\n     \r\n    for (int i = 0; i < [codes count]; i++)\r\n    {\r\n        Roi *roi = [codes objectAtIndex:i];\r\n         \r\n        code = 1;\r\n    }\r\n     \r\n    VSLog(@\"Multiple QR / bar codes detected --> %@\", code);\r\n}\r\n```\r\n\r\n## Crop frames\r\n\r\nIf you don't want to analyse the whole frame but part of it, you can crop it:\r\n\r\n```objective-c\r\n- (void)addCropRect\r\n{\r\n    CGRect myRect = CGRectMake(20, 20, 200, 125);\r\n     \r\n    [self addRectToView:myRect];\r\n     \r\n    [_myVs setImageCropRect:myRect];\r\n}\r\n```\r\n\r\n## Featured Apps using the VS Framework\r\n\r\n![](https://s3-us-west-1.amazonaws.com/aumentia/apps/klikaklu/klikaklu_logo_transparent_small.png)\r\n\r\nKlikaklu is a photo hunt game for [iOS](http://itunes.apple.com/us/app/klikaklu/id541735944?ls=1&mt=8) that uses your phone's GPS, camera, and advanced image matching technology. It's a great way to quickly create and play treasure hunts! \r\n\r\nShare hunts privately with friends and family, or leave them in public places for others to find. Lead people to new and interesting spots. Reveal secrets and rewards when they crack your clues.\r\n\r\nNo geocaching boxes or QR codes are necessary, so you can create hunts in national parks, museums, airport terminals, doctors offices - any place you want to add an element of challenge or mystery, share as special with someone, keep the kids busy, or while away some time.\r\n\r\n<br/>\r\n\r\n&nbsp;&nbsp;&nbsp;\r\n![](https://s3-us-west-1.amazonaws.com/aumentia/apps/klikaklu/klikaklu_screenshot_02_small.png)\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \r\n![](https://s3-us-west-1.amazonaws.com/aumentia/apps/klikaklu/klikaklu_screenshot_04_small.png) \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\r\n![](https://s3-us-west-1.amazonaws.com/aumentia/apps/klikaklu/klikaklu_screenshot_05_small.png)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}