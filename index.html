<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Visual Search Framework [iOS] : Aumentia Visual Search Framework: Image Recognition and QR / bar code reader">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Visual Search Framework [iOS]</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/aumentia/HelloVisualSearch_iOS">View on GitHub</a>

          <h1 id="project_title">Visual Search Framework [iOS]</h1>
          <h2 id="project_tagline">Aumentia Visual Search Framework: Image Recognition and QR / bar code reader</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/aumentia/HelloVisualSearch_iOS/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/aumentia/HelloVisualSearch_iOS/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="the-visual-search-framework-includes" class="anchor" href="#the-visual-search-framework-includes" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Visual Search Framework includes:</h3>

<p><img src="https://s3-us-west-1.amazonaws.com/aumentia/wiki/home/icon55.png" alt="VS Framework Logo">
<img src="https://s3-us-west-1.amazonaws.com/aumentia/wiki/home/visualsearch_small.png" alt="Recognise within milliseconds any image"></p>

<ul>
<li>Add visual search to your app.</li>
<li>Real time image matching (50-100 images per pool).</li>
<li>Insert images from local resources: works offline!</li>
<li>Insert images from URL.</li>
<li>White Label.</li>
<li>QR code scan support.</li>
<li>Scan up to 4 QR / bar codes at a time.</li>
<li>Define you matching areas: Regions of Interest.</li>
<li>Match images and QR codes simultaneously </li>
<li><strong>arm64 support</strong></li>
</ul>

<h2>
<a id="new-motion-recognition" class="anchor" href="#new-motion-recognition" aria-hidden="true"><span class="octicon octicon-link"></span></a>NEW: Motion Recognition</h2>

<ul>
<li>Define virtual buttons (regions of interest) to detect motion</li>
</ul>

<h2>
<a id="content" class="anchor" href="#content" aria-hidden="true"><span class="octicon octicon-link"></span></a>Content</h2>

<ul>
<li> <a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Configure-VS-Framework">Configure VS Framework</a>
</li>
<li> <a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Add-&amp;-Remove-Images">Add &amp; Remove Images</a>
</li>
<li> <a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Read-QR---bar-codes">Read QR bar codes</a>
</li>
<li> <a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Crop-frames">Crop frames</a>
</li>
<li> <a href="http://api.aumentia.com/visualsearch/">API</a>
</li>
<li> <a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Featured-Apps-using-the-VS-Framework">Featured Apps using the VS Framework</a>

<ul>
<li><a href="https://github.com/aumentia/HelloVisualSearch_iOS/wiki/Featured-Apps---Klikaklu">Klikaklu</a></li>
</ul>
</li>
</ul>

<h2>
<a id="configure-the-framework" class="anchor" href="#configure-the-framework" aria-hidden="true"><span class="octicon octicon-link"></span></a>Configure the framework</h2>

<ul>
<li>Include the following frameworks</li>
</ul>

<p><img src="https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs1.png" alt="Include these frameworks"></p>

<ul>
<li>Add the below linker flags:
<code>-mthumb -lstdc++ -lz -lm -mfpu=neon -mtune=cortex-a8</code> </li>
</ul>

<p><img src="https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs2.png" alt="Other Linker Flags"></p>

<ul>
<li>Include the <strong>VS.framework</strong> and add its protocols </li>
</ul>

<div class="highlight highlight-objective-c"><pre>#<span class="pl-k">import</span> <span class="pl-s"><span class="pl-pds">&lt;</span>VS/vsPlugin.h<span class="pl-pds">&gt;</span></span>
...

<span class="pl-k">@interface</span> <span class="pl-en">ViewController</span> : <span class="pl-e">UIViewController</span>&lt;imageMatchedProtocol, QRMatchedProtocol,...&gt;

<span class="pl-k">@end</span></pre></div>

<ul>
<li>The .m file where you include the framework must be compiled supporting cpp, so change the “<strong>File Type</strong>” to “<strong>Objective-C++ Source</strong>“. </li>
</ul>

<p><img src="https://s3-us-west-1.amazonaws.com/aumentia/wiki/configure/vs3.png" alt="objc++"></p>

<ul>
<li>Add your own camera. You should create a protocol that will be receiving each output frame. We will send this frame to the engine to analyse it.
We provide the CaptureSessionManager class to take care of all the camera aspects.
You just will need to set it up:</li>
</ul>

<div class="highlight highlight-objective-c"><pre>#<span class="pl-k">pragma mark</span> - Add external camera

- (<span class="pl-k">void</span>)initCapture {

    <span class="pl-c">// init capture manager</span>
    _captureManager = [[CaptureSessionManager <span class="pl-c1">alloc</span>] <span class="pl-c1">init</span>];

    _captureManager.<span class="pl-smi">delegate</span> = self;

    <span class="pl-c">// set video streaming quality</span>
    _captureManager.<span class="pl-smi">captureSession</span>.<span class="pl-smi">sessionPreset</span> = AVCaptureSessionPresetMedium;   <span class="pl-c">//480x360</span>

    [_captureManager <span class="pl-c1">setOutPutSetting:</span>[<span class="pl-c1">NSNumber</span> <span class="pl-c1">numberWithInt:</span><span class="pl-c1">kCVPixelFormatType_32BGRA</span>]]; <span class="pl-c">//kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange</span>

    [_captureManager <span class="pl-c1">addVideoInput:</span>AVCaptureDevicePositionBack]; <span class="pl-c">//AVCaptureDevicePositionFront / AVCaptureDevicePositionBack</span>
    [_captureManager <span class="pl-c1">addVideoOutput</span>];
    [_captureManager <span class="pl-c1">addVideoPreviewLayer</span>];

    <span class="pl-c1">CGRect</span> layerRect = self.<span class="pl-smi">view</span>.<span class="pl-smi">bounds</span>;

    [[_captureManager <span class="pl-c1">previewLayer</span>] <span class="pl-c1">setOpaque:</span> <span class="pl-c1">0</span>];
    [[_captureManager <span class="pl-c1">previewLayer</span>] <span class="pl-c1">setBounds:</span>layerRect ];
    [[_captureManager <span class="pl-c1">previewLayer</span>] <span class="pl-c1">setPosition:</span><span class="pl-c1">CGPointMake</span>( <span class="pl-c1">CGRectGetMidX</span>(layerRect), <span class="pl-c1">CGRectGetMidY</span>(layerRect) ) ];

    <span class="pl-c">// create a view, on which we attach the AV Preview layer</span>
    _cameraView = [[UIView <span class="pl-c1">alloc</span>] <span class="pl-c1">initWithFrame:</span><span class="pl-v">self</span>.view.bounds];
    [[_cameraView <span class="pl-c1">layer</span>] <span class="pl-c1">addSublayer:</span>[_captureManager <span class="pl-c1">previewLayer</span>]];

    <span class="pl-c">// add the view we just created as a subview to the View Controller's view</span>
    [<span class="pl-v">self</span>.view <span class="pl-c1">addSubview:</span> _cameraView];

    <span class="pl-c">// start !</span>
    [<span class="pl-v">self</span> <span class="pl-c1">performSelectorInBackground:</span><span class="pl-k">@selector</span>(<span class="pl-c1">start_captureManager</span>) <span class="pl-c1">withObject:</span><span class="pl-c1">nil</span>];

}

- (<span class="pl-k">void</span>)removeCapture
{
    [_captureManager.captureSession <span class="pl-c1">stopRunning</span>];
    [_cameraView <span class="pl-c1">removeFromSuperview</span>];
    _captureManager     = <span class="pl-c1">nil</span>;
    _cameraView         = <span class="pl-c1">nil</span>;
}

- (<span class="pl-k">void</span>)start_captureManager
{
    @autoreleasepool
    {
        [[_captureManager <span class="pl-c1">captureSession</span>] <span class="pl-c1">startRunning</span>];
    }
}</pre></div>

<p>and implement its callbacks:</p>

<div class="highlight highlight-objective-c"><pre>#<span class="pl-k">pragma mark</span> - External Camera Delegates

- (<span class="pl-k">void</span>)processNewCameraFrameRGB:(CVImageBufferRef)cameraFrame
{
    [_myVs <span class="pl-c1">processRGBFrame:</span>cameraFrame <span class="pl-c1">saveImageToPhotoAlbum:</span><span class="pl-c1">NO</span> ];
}

- (<span class="pl-k">void</span>)processNewCameraFrameYUV:(CVImageBufferRef)cameraFrame
{
    [_myVs <span class="pl-c1">processYUVFrame:</span>cameraFrame <span class="pl-c1">saveImageToPhotoAlbum:</span><span class="pl-c1">NO</span>];
}</pre></div>

<h2>
<a id="add--remove-images" class="anchor" href="#add--remove-images" aria-hidden="true"><span class="octicon octicon-link"></span></a>Add &amp; Remove Images</h2>

<p>The library matches the camera output frames with the images stored in its database. The search process takes few ms, this means it is real time. The processing time depends on the device and on the amount of images you add to the system. Typically you can add around <strong>50 images up to 100</strong> in the most powerful devices.
You can both add images from <strong>URL</strong> or from your <strong>local</strong> resources.
You can also set up your unique Id or let the library do it for you.</p>

<p>To add images you can use these functions:</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">NSInteger</span>) insertImage:(UIImage*)image;

- (<span class="pl-k">NSInteger</span>) insertImageFromURL:(<span class="pl-c1">NSURL</span>*)imageUrl;

- (<span class="pl-k">BOOL</span>) insertImage:(UIImage*)image withId:(<span class="pl-k">NSInteger</span>)uId;

- (<span class="pl-k">BOOL</span>) insertImageFromURL:(<span class="pl-c1">NSURL</span>*)imageUrl withId:(<span class="pl-k">NSInteger</span>)uId;</pre></div>

<p>You can also delete a single image providing its unique id:</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">BOOL</span>) deleteImage:(<span class="pl-k">NSInteger</span>)uId;</pre></div>

<p>Or delete all the images in the db.</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">BOOL</span>) deleteAllImages;</pre></div>

<h3>
<a id="how-to-create-a-good-pool" class="anchor" href="#how-to-create-a-good-pool" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to create a “good pool”</h3>

<p>A good pool is a group of images that have good features, are different between them and can be easily matched without getting any false positive. In order to assure that you create good pools we provide several functions:</p>

<ul>
<li><p><strong>setMatchingThreshold</strong>: The images added to the system receive a punctuation between 0 and 10 indicating how “rich” is the image (amounf of good features for matching). The more close to 10, easier is to match the image and more difficult is to get a false positive.
Setting this param, the user decides the minimum quality of his pool of images.</p></li>
<li><p>Before adding an image to your pool you can get its punctuation with the <strong>getImageScore</strong> function.</p></li>
<li>
<p>You can also adjust the <strong>MinFeatures</strong> and <strong>MaxFeatures</strong> params:</p>

<p><strong>MinFeatures</strong>: Minimum amount of features accepted to insert an image in the system.</p>

<ul>
<li>The higher it is the most feature-rich images will be required to be inserted.</li>
<li>This value is related with the threshold: the higher the most restrictive the threshold will be.</li>
<li><strong>Default value is 50.</strong></li>
</ul>

<p><strong>MaxFeatures</strong>: Maximum amount of features accepted to match an image.</p>

<ul>
<li>When an image / frame is going to be matched against the images already inserted in the system, the engine</li>
<li>extract the best features and compares them with the ones of the images in the system.</li>
<li>The higher it is the most features will be accepted in the matching process.</li>
<li>The higher it is the better will be the matching quality but the matching speed will be reduced.</li>
<li><strong>Default value is 50.</strong></li>
</ul>
</li>
<li><p>It is recommended to use the motion filter. This filter checks if the device is moving and if so, it does not look for matches avoiding false positive with undefined frames while moving: </p></li>
</ul>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)initMotionDetection;

- (<span class="pl-k">void</span>)removeMotionDetection;</pre></div>

<h3>
<a id="detection-callbacks" class="anchor" href="#detection-callbacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Detection callbacks</h3>

<p>First you need to implement the <strong>CaptureSessionManger</strong> class callbacks. Remember that those callbacks will provide you the video feed frames, frames that you will send to be analysed by the library.</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)processNewCameraFrameRGB:(CVImageBufferRef)cameraFrame
{
    [_myVs <span class="pl-c1">processRGBFrame:</span>cameraFrame <span class="pl-c1">saveImageToPhotoAlbum:</span><span class="pl-c1">NO</span> ];
}</pre></div>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)processNewCameraFrameYUV:(CVImageBufferRef)cameraFrame
{
    [_myVs <span class="pl-c1">processYUVFrame:</span>cameraFrame <span class="pl-c1">saveImageToPhotoAlbum:</span><span class="pl-c1">NO</span>];
}</pre></div>

<p>Then the engine will give you back the matching results: -1 if no image is recognised, != -1 if an image has been matched, being that result its unique id.</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)imageMatchedResult:(<span class="pl-k">NSInteger</span>)uId
{
    <span class="pl-k">if</span> (uId != -<span class="pl-c1">1</span>)
    {
        <span class="pl-c1">VSLog</span>(<span class="pl-s"><span class="pl-pds">@"</span>Image detected --&gt; <span class="pl-c1">%d</span><span class="pl-pds">"</span></span>, uId);
    }
}</pre></div>

<h2>
<a id="qr--bar-codes" class="anchor" href="#qr--bar-codes" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR / bar codes</h2>

<p>This library is capable also to read QR and bar codes.
The supported standards are:</p>

<ul>
<li>    UPC-A</li>
<li>    UPC-E</li>
<li>    EAN-8</li>
<li>    EAN-13</li>
<li>    Code 39</li>
<li>    Code 93</li>
<li>    Code 128</li>
<li>    ITF</li>
<li>    Codabar</li>
<li>    RSS-14 (all variants)</li>
<li>    QR Code</li>
<li>    Data Matrix</li>
<li>    Aztec (‘beta’ quality)</li>
<li>    PDF 417 (‘alpha’ quality)</li>
</ul>

<p>In order to enable this feature, set <strong>search_mode</strong> to <strong>search_QRcodes</strong> or <strong>search_all</strong></p>

<h3>
<a id="multiple-qr--bar-codes" class="anchor" href="#multiple-qr--bar-codes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple QR / bar codes</h3>

<p>You can also read <strong>multiple QR / bar codes a time</strong>. To do that you will need to define ROIs, regions of interest, where to “look for” readable codes.</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)addQRRois
{
    <span class="pl-c">// Add regions to match several QR / bar codes</span>
    Roi *ROI1 = [[Roi <span class="pl-c1">alloc</span>] <span class="pl-c1">initWithRect:</span><span class="pl-c1">CGRectMake</span>(<span class="pl-c1">0</span>, <span class="pl-c1">0</span>, <span class="pl-c1">160</span>, <span class="pl-c1">240</span>)];
    Roi *ROI2 = [[Roi <span class="pl-c1">alloc</span>] <span class="pl-c1">initWithRect:</span><span class="pl-c1">CGRectMake</span>(<span class="pl-c1">0</span>, <span class="pl-c1">240</span>, <span class="pl-c1">160</span>, <span class="pl-c1">240</span>)];
    Roi *ROI3 = [[Roi <span class="pl-c1">alloc</span>] <span class="pl-c1">initWithRect:</span><span class="pl-c1">CGRectMake</span>(<span class="pl-c1">160</span>, <span class="pl-c1">0</span>, <span class="pl-c1">160</span>, <span class="pl-c1">240</span>)];
    Roi *ROI4 = [[Roi <span class="pl-c1">alloc</span>] <span class="pl-c1">initWithRect:</span><span class="pl-c1">CGRectMake</span>(<span class="pl-c1">160</span>, <span class="pl-c1">240</span>, <span class="pl-c1">160</span>, <span class="pl-c1">240</span>)];

    <span class="pl-c">// Add them to the system</span>
    [_myVs <span class="pl-c1">addQRRect:</span>ROI1];
    [_myVs <span class="pl-c1">addQRRect:</span>ROI2];
    [_myVs <span class="pl-c1">addQRRect:</span>ROI3];
    [_myVs <span class="pl-c1">addQRRect:</span>ROI4];
}</pre></div>

<h3>
<a id="qr-codes-callbacks" class="anchor" href="#qr-codes-callbacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR codes callbacks</h3>

<p>When a single or multiple QR / bar code is/are read, the QRMatchedProtocol protocol will give you the value/s:</p>

<div class="highlight highlight-objective-c"><pre>
- (<span class="pl-k">void</span>)singleQRMatchedResult:(<span class="pl-c1">NSString</span> *)res
{
    <span class="pl-k">if</span> ( ![res <span class="pl-c1">isEqualToString:</span><span class="pl-s"><span class="pl-pds">@"</span><span class="pl-pds">"</span></span>])
    {
        <span class="pl-c1">VSLog</span>(<span class="pl-s"><span class="pl-pds">@"</span>QR / bar code detected --&gt; <span class="pl-c1">%@</span><span class="pl-pds">"</span></span>, res);
    }
}

- (<span class="pl-k">void</span>)multipleQRMatchedResult:(<span class="pl-c1">NSArray</span> *)codes
{
    <span class="pl-c1">NSString</span> *code = <span class="pl-s"><span class="pl-pds">@"</span><span class="pl-pds">"</span></span>;

    <span class="pl-k">for</span> (<span class="pl-k">int</span> i = <span class="pl-c1">0</span>; i &lt; [codes <span class="pl-c1">count</span>]; i++)
    {
        Roi *roi = [codes <span class="pl-c1">objectAtIndex:</span>i];

        code = <span class="pl-c1">1</span>;
    }

    <span class="pl-c1">VSLog</span>(<span class="pl-s"><span class="pl-pds">@"</span>Multiple QR / bar codes detected --&gt; <span class="pl-c1">%@</span><span class="pl-pds">"</span></span>, code);
}</pre></div>

<h2>
<a id="crop-frames" class="anchor" href="#crop-frames" aria-hidden="true"><span class="octicon octicon-link"></span></a>Crop frames</h2>

<p>If you don't want to analyse the whole frame but part of it, you can crop it:</p>

<div class="highlight highlight-objective-c"><pre>- (<span class="pl-k">void</span>)addCropRect
{
    <span class="pl-c1">CGRect</span> myRect = <span class="pl-c1">CGRectMake</span>(<span class="pl-c1">20</span>, <span class="pl-c1">20</span>, <span class="pl-c1">200</span>, <span class="pl-c1">125</span>);

    [<span class="pl-v">self</span> <span class="pl-c1">addRectToView:</span>myRect];

    [_myVs <span class="pl-c1">setImageCropRect:</span>myRect];
}</pre></div>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Visual Search Framework [iOS] maintained by <a href="https://github.com/aumentia">aumentia</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
